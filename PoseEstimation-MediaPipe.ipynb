{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoseEstimation-MediaPipe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOSk4DWhBXvv",
        "outputId": "afcefd49-973b-4bb6-fe95-b8c68592f211"
      },
      "source": [
        "pip install mediapipe"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/42/af2507a86a81e4cce0d3adcb764a755f397238d0c7bee2d99794fdca2fc5/mediapipe-0.8.3.1-cp37-cp37m-manylinux2014_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 66kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (20.3.0)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (54.0.0)\n",
            "Installing collected packages: dataclasses, mediapipe\n",
            "Successfully installed dataclasses-0.6 mediapipe-0.8.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdWc3kaXDQw9"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XKGoDVDQw-"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4_85wfeBRyE"
      },
      "source": [
        "import cv2\r\n",
        "import mediapipe as mp\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import math\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "\r\n",
        "def get_actual_angle(x1, y1, x2, y2):\r\n",
        "  return math.atan((y2-y1)/(x2-x1)) * 180/ math.pi\r\n",
        "\r\n",
        "def get_angle(x1, y1, x2, y2): \r\n",
        "  return math.atan((y2-y1)/(x2-x1)) * 180/ math.pi\r\n",
        "\r\n",
        "mp_drawing = mp.solutions.drawing_utils\r\n",
        "mp_pose = mp.solutions.pose\r\n",
        "mp_holistic = mp.solutions.holistic\r\n",
        "count = 1\r\n",
        "plt.figure(figsize=(6,6))\r\n",
        "skeletons = []\r\n",
        "# For static images:\r\n",
        "file_list = ['AmitHands.jpeg','SagarHands.jpeg']\r\n",
        "with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:\r\n",
        "  for idx, file in enumerate(file_list):\r\n",
        "    image = cv2.imread(file)\r\n",
        "    image_height, image_width, _ = image.shape\r\n",
        "    # Convert the BGR image to RGB before processing.\r\n",
        "    print(image.shape)\r\n",
        "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\r\n",
        "\r\n",
        "    if not results.pose_landmarks:\r\n",
        "      continue\r\n",
        "\r\n",
        "    \r\n",
        "    '''print(\r\n",
        "        f'Nose coordinates: ('\r\n",
        "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\r\n",
        "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})'\r\n",
        "    )'''\r\n",
        "    \r\n",
        "    # Draw pose landmarks on the image.\r\n",
        "    annotated_image = image.copy()\r\n",
        "    \r\n",
        "    # Use mp_pose.UPPER_BODY_POSE_CONNECTIONS for drawing below when\r\n",
        "    # upper_body_only is set to True.\r\n",
        "    mp_drawing.draw_landmarks(\r\n",
        "        annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\r\n",
        "    dark_canvas = np.zeros(image.shape, np.uint8)\r\n",
        "    mp_drawing.draw_landmarks(\r\n",
        "      dark_canvas, results.pose_landmarks, mp_pose.POSE_CONNECTIONS \r\n",
        "    )\r\n",
        "    cv2.imwrite('skeleton_image' + str(idx) + '.png', dark_canvas)\r\n",
        "    cv2.imwrite('annotated_image' + str(idx) + '.png', annotated_image)\r\n",
        "\r\n",
        "    annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\r\n",
        "    plt.subplot(2,2,count)\r\n",
        "    plt.imshow(annotated_image)\r\n",
        "    plt.title(file)\r\n",
        "    plt.yticks([])\r\n",
        "    plt.xticks([])\r\n",
        "\r\n",
        "    plt.subplot(2,2,count+1)\r\n",
        "    plt.imshow(dark_canvas)\r\n",
        "    plt.title(file)\r\n",
        "    plt.yticks([])\r\n",
        "    plt.xticks([])\r\n",
        "\r\n",
        "    count += 2\r\n",
        "\r\n",
        "    skeletons.append(results)\r\n",
        "'''\r\n",
        "for index in range(32):\r\n",
        "  for result in skeletons:\r\n",
        "    print(result.pose_landmarks.landmark[index].x * image_width, result.pose_landmarks.landmark[index].y * image_height)\r\n",
        "    \r\n",
        "  print(\"====\")'''\r\n",
        "angles_images = []\r\n",
        "edges = [(14,16), (12,14), (11,12), (13,11), (15, 13), (24,12), (23,11), (23,24), (26,24), (25,23), (28,26), (27,25)]\r\n",
        "actual_angles = []\r\n",
        "visibilities = []\r\n",
        "for result in skeletons:\r\n",
        "  angles_image = []\r\n",
        "  actual_angle = []\r\n",
        "  visibility = []\r\n",
        "  '''print(result.pose_landmarks.landmark[14].x  * image_width, \r\n",
        "        result.pose_landmarks.landmark[14].y * image_height, \r\n",
        "        result.pose_landmarks.landmark[16].x * image_width, \r\n",
        "        result.pose_landmarks.landmark[16].y * image_height )\r\n",
        "\r\n",
        "  print(result.pose_landmarks.landmark[13].x  * image_width, \r\n",
        "        result.pose_landmarks.landmark[13].y * image_height, \r\n",
        "        result.pose_landmarks.landmark[15].x * image_width, \r\n",
        "        result.pose_landmarks.landmark[15].y * image_height)'''\r\n",
        "  for edge in edges:\r\n",
        "    start, dest = edge\r\n",
        "  \r\n",
        "    angles_image.append(get_angle(result.pose_landmarks.landmark[start].x  * image_width, \r\n",
        "                                  result.pose_landmarks.landmark[start].y * image_height, \r\n",
        "                                  result.pose_landmarks.landmark[dest].x * image_width, \r\n",
        "                                  result.pose_landmarks.landmark[dest].y * image_height ))    \r\n",
        "    visibility.append(result.pose_landmarks.landmark[start].visibility+result.pose_landmarks.landmark[dest].visibility)\r\n",
        "  angles_images.append(angles_image)\r\n",
        "  visibilities.append(visibility)\r\n",
        "\r\n",
        "'''for angles_image in angles_images:\r\n",
        "  print(angles_image)\r\n",
        "'''\r\n",
        "difference = [0 for i in range(len(edges))]\r\n",
        "for i in range(len(edges)):\r\n",
        "  difference[i] = abs(angles_images[1][i] - angles_images[0][i])\r\n",
        "  if angles_images[1][i] < 0:\r\n",
        "      difference[i] = min(abs(180 - abs(angles_images[1][i]) - angles_images[0][i]), difference[i])\r\n",
        "  elif angles_images[0][i] < 0:\r\n",
        "      difference[i] = min(abs(180 - abs(angles_images[0][i]) - angles_images[1][i]), difference[i])\r\n",
        "      \r\n",
        "match_percent = [(90-difference[i])/90 * 100 for i in range(len(edges))]\r\n",
        "weighted_mask = [8, 4, 1, 4, 8, 1, 1, 1, 4, 4, 8, 8]\r\n",
        "final_percentage_each = [match_percent[i] * weighted_mask[i]/sum(weighted_mask) \r\n",
        "                        for i in range(len(edges))]\r\n",
        "\r\n",
        "print(angles_images[0])\r\n",
        "print(angles_images[1])\r\n",
        "print(difference)\r\n",
        "print(f\"MATCH PERCENTAGE: {round(sum(final_percentage_each),2)}%\")\r\n",
        "\r\n",
        "#print(difference)\r\n",
        "#print(values)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVVe9biXO5fy"
      },
      "source": [
        "import cv2\r\n",
        "import mediapipe as mp\r\n",
        "mp_drawing = mp.solutions.drawing_utils\r\n",
        "mp_pose = mp.solutions.pose\r\n",
        "mp_holistic = mp.solutions.holistic\r\n",
        "\r\n",
        "video_file = 'AmitHands.mp4'\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "cap = cv2.VideoCapture(video_file)\r\n",
        "count = 0\r\n",
        "with mp_pose.Pose(\r\n",
        "    min_detection_confidence=0.5,\r\n",
        "    min_tracking_confidence=0.5) as pose:\r\n",
        "  while cap.isOpened():\r\n",
        "    success, image = cap.read()\r\n",
        "    if not success:\r\n",
        "\r\n",
        "      print(\"Ignoring empty camera frame.\")\r\n",
        "      # If loading a video, use 'break' instead of 'continue'.\r\n",
        "      break\r\n",
        "      #continue\r\n",
        "    count += 1\r\n",
        "    # Flip the image horizontally for a later selfie-view display, and convert\r\n",
        "    # the BGR image to RGB.\r\n",
        "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\r\n",
        "    # To improve performance, optionally mark the image as not writeable to\r\n",
        "    # pass by reference.\r\n",
        "    image.flags.writeable = False\r\n",
        "    results = pose.process(image)\r\n",
        "\r\n",
        "    # Draw the pose annotation on the image.\r\n",
        "    image.flags.writeable = True\r\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
        "    mp_drawing.draw_landmarks(\r\n",
        "        image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\r\n",
        "    cv2_imshow(image)\r\n",
        "    if cv2.waitKey(5) & 0xFF == 27:\r\n",
        "      break\r\n",
        "print(count)\r\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}